# Snowflake Iceberg V3 Comprehensive Guide - Configuration Template
# Copy this file to config.env and update with your values

# ============================================
# REQUIRED: Snowflake CLI Connection
# ============================================
# Name of your Snowflake CLI connection (configured via: snow connection add)
# See: https://docs.snowflake.com/en/developer-guide/snowflake-cli/connecting/specify-credentials
SNOWFLAKE_CONNECTION="default"

# ============================================
# REQUIRED: Snowflake Account Info (for Python SDK)
# ============================================
# These are needed for the streaming Python script which uses snowflake-connector-python
# Use the same values as your CLI connection
SNOWFLAKE_ACCOUNT="your_account_identifier"
SNOWFLAKE_USER="your_username"

# Optional: Authentication method
# If you have a password or Personal Access Token, add it here:
# SNOWFLAKE_PASSWORD="your_password_or_pat"
#
# Authenticator options (only needed if not using password):
# - externalbrowser (default): Opens browser for SSO
# - snowflake: Password auth (requires SNOWFLAKE_PASSWORD)
# - snowflake_jwt: Key-pair auth
# SNOWFLAKE_AUTHENTICATOR="externalbrowser"

# ============================================
# Snowflake Object Names
# ============================================
SNOWFLAKE_ROLE="ACCOUNTADMIN"
SNOWFLAKE_WAREHOUSE="FLEET_ANALYTICS_WH"
SNOWFLAKE_DATABASE="FLEET_ANALYTICS_DB"

# ============================================
# OPTIONAL: Network Policy for Streaming
# ============================================
# Set to true if you have connection issues with the Python streaming script.
# This is often needed when connecting from a VPN or corporate network.
# Creates a network policy allowing inbound connections.
ENABLE_NETWORK_POLICY=false

# ============================================
# EXTERNAL VOLUME CONFIGURATION
# ============================================
# Iceberg tables require an external volume pointing to your cloud storage.
# Choose ONE of the options below:

# OPTION A: Use an existing external volume (if you already have one configured)
USE_EXISTING_VOLUME=false
EXISTING_VOLUME_NAME=""

# OPTION B: Create a new external volume
# Set USE_EXISTING_VOLUME=false and configure your storage provider below
STORAGE_PROVIDER="S3"  # Options: S3, GCS, AZURE

# ============================================
# AWS S3 Configuration
# ============================================
S3_BUCKET_NAME=""
S3_PATH="iceberg/fleet-analytics/"
AWS_ROLE_ARN=""
AWS_REGION="us-west-2"
# Optional encryption settings
S3_ENCRYPTION_TYPE="AWS_SSE_S3"  # Options: AWS_SSE_S3, AWS_SSE_KMS, NONE
S3_KMS_KEY_ID=""  # Only needed if using AWS_SSE_KMS

# ============================================
# Google Cloud Storage Configuration
# ============================================
GCS_BUCKET_NAME=""
GCS_PATH="iceberg/fleet-analytics/"
# Note: After setup, you'll need to grant the Snowflake service account access

# ============================================
# Azure Storage Configuration
# (Works for Azure Blob, ADLS Gen2, and OneLake)
# See: https://docs.snowflake.com/en/user-guide/tables-iceberg-configure-external-volume-azure
# ============================================
AZURE_TENANT_ID=""
AZURE_STORAGE_ACCOUNT=""
AZURE_CONTAINER=""
AZURE_PATH="iceberg/fleet-analytics/"

# For OneLake, use this endpoint format instead of the standard blob endpoint:
# onelake.dfs.fabric.microsoft.com/<workspace-guid>/<lakehouse-guid>.Lakehouse/Files/
# Set this to true if using OneLake
USE_ONELAKE=false
ONELAKE_WORKSPACE_GUID=""
ONELAKE_LAKEHOUSE_GUID=""

# ============================================
# STREAMING CONFIGURATION
# ============================================
# Duration for streaming simulation (in seconds, max 300)
STREAMING_DURATION=300
# Number of vehicles to simulate
STREAMING_VEHICLE_COUNT=50
# Events per second per vehicle
STREAMING_EVENTS_PER_SECOND=2

# ============================================
# EXTERNAL LINEAGE (Optional)
# ============================================
# Enable external lineage to show data flow from IoT source to Iceberg table
# Requires INGEST LINEAGE privilege on account
# See: https://docs.snowflake.com/en/user-guide/external-lineage
ENABLE_EXTERNAL_LINEAGE=true

# Simulated IoT/MQTT broker where vehicles publish telemetry
# Common real-world examples:
#   - mqtt://fleet-iot-gateway.example.com (generic MQTT broker)
#   - awsiot://<account-id>.iot.us-west-2.amazonaws.com (AWS IoT Core)
#   - azure-iothub://your-hub.azure-devices.net (Azure IoT Hub)
#   - api://samsara.com/fleet (Samsara telematics API)
#   - api://geotab.com/myg (Geotab telematics API)
IOT_BROKER_NAMESPACE="mqtt://fleet-iot-gateway.example.com"
IOT_SOURCE_NAME="Fleet Vehicle Telematics"
IOT_TOPIC_PATTERN="fleet/vehicles/+/telemetry"

# ============================================
# SPARK INTEROPERABILITY (Optional)
# ============================================
# Account identifier for Polaris REST API - may differ from SNOWFLAKE_ACCOUNT
# Format: orgname-accountname OR account_locator.region.cloud
# Example: "myorg-myaccount" or "xy12345.us-west-2.aws"
# To find yours, run in Snowflake: SELECT CURRENT_ORGANIZATION_NAME() || '-' || CURRENT_ACCOUNT_NAME();
# See: https://docs.snowflake.com/en/user-guide/admin-account-identifier
SNOWFLAKE_ACCOUNT_URL=""

# OAuth tokens for Spark catalog authentication
SNOWFLAKE_ACCOUNTADMIN_TOKEN=""
SNOWFLAKE_FLEET_ANALYST_TOKEN=""
