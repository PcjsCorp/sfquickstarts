{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Interoperability with Snowflake Iceberg V3 Tables\n",
    "\n",
    "This notebook demonstrates querying Snowflake-managed Iceberg V3 tables from Apache Spark,\n",
    "with access controls enforced via Snowflake Horizon catalog.\n",
    "\n",
    "## Prerequisites\n",
    "- Apache Spark 4.0+ (required for VARIANT support)\n",
    "- Python 3.10+\n",
    "- Completed the Snowflake setup from the main guide\n",
    "\n",
    "## Cloud Storage Bundles\n",
    "\n",
    "Iceberg requires cloud-specific SDK bundles to access storage. The Spark config below uses **AWS** by default.\n",
    "\n",
    "| Cloud Provider | Bundle to Add |\n",
    "|----------------|---------------|\n",
    "| **AWS S3** | `org.apache.iceberg:iceberg-aws-bundle:1.10.1` |\n",
    "| **Google Cloud** | `org.apache.iceberg:iceberg-gcp-bundle:1.10.1` |\n",
    "| **Azure** | `org.apache.iceberg:iceberg-azure-bundle:1.10.1` |\n",
    "\n",
    "Update `spark.jars.packages` in Cell 3 if using GCP or Azure storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load configuration from the same config.env used during setup\n",
    "load_dotenv('config.env')\n",
    "\n",
    "SNOWFLAKE_ACCOUNT = os.getenv('SNOWFLAKE_ACCOUNT')\n",
    "SNOWFLAKE_USER = os.getenv('SNOWFLAKE_USER')\n",
    "SNOWFLAKE_DATABASE = os.getenv('SNOWFLAKE_DATABASE', 'FLEET_ANALYTICS_DB')\n",
    "\n",
    "# For Iceberg REST API, dashes must be replaced with underscores in account identifier\n",
    "# IMPORTANT: Set your Snowflake account identifier for the REST API endpoint\n",
    "# Use one of these formats (see https://docs.snowflake.com/en/user-guide/admin-account-identifier):\n",
    "#   - orgname-accountname (e.g., \"myorg-myaccount\")\n",
    "#   - account_locator.region.cloud (e.g., \"xy12345.us-west-2.aws\")\n",
    "# To find yours, run in Snowflake: SELECT CURRENT_ORGANIZATION_NAME() || '-' || CURRENT_ACCOUNT_NAME();\n",
    "SNOWFLAKE_ACCOUNT_URL = os.getenv('SNOWFLAKE_ACCOUNT_URL', SNOWFLAKE_ACCOUNT)\n",
    "SNOWFLAKE_ACCOUNTADMIN_TOKEN = os.getenv('SNOWFLAKE_ACCOUNTADMIN_TOKEN')\n",
    "SNOWFLAKE_FLEET_ANALYST_TOKEN = os.getenv('SNOWFLAKE_FLEET_ANALYST_TOKEN')\n",
    "SCALA_VERSION = '2.13'\n",
    "ICEBERG_VERSION = '1.10.1'\n",
    "\n",
    "print(f\"Snowflake Account (REST endpoint): {SNOWFLAKE_ACCOUNT_URL}\")\n",
    "print(f\"Database: {SNOWFLAKE_DATABASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Spark Session with Horizon Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configuration\n",
    "SNOWFLAKE_PASSWORD = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "SNOWFLAKE_ROLE = 'ACCOUNTADMIN'\n",
    "SNOWFLAKE_SCHEMA = 'RAW'\n",
    "SNOWFLAKE_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE', 'FLEET_ANALYTICS_WH')\n",
    "SF_URL = f\"{SNOWFLAKE_ACCOUNT_URL}.snowflakecomputing.com\"\n",
    "\n",
    "# Versions - Note: Spark 3.5 required for Snowflake Connector masking support\n",
    "SNOWFLAKE_JDBC_VERSION = \"3.24.0\"\n",
    "SNOWFLAKE_SPARK_CONNECTOR_VERSION = \"3.1.6\"\n",
    "\n",
    "# Create Spark session with Iceberg and Snowflake catalog configuration\n",
    "# Note: \n",
    "# - driver.host and bindAddress ensure Spark uses localhost (avoids VPN issues)\n",
    "# - Using Spark 4.0 + Iceberg 1.10.1 for native VARIANT support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Fleet Analytics - Iceberg V3 Interop\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            f\"org.apache.iceberg:iceberg-spark-runtime-4.0_{SCALA_VERSION}:{ICEBERG_VERSION},\"\n",
    "            f\"org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION},\"\n",
    "            f\"net.snowflake:snowflake-jdbc:{SNOWFLAKE_JDBC_VERSION},\"\n",
    "            f\"net.snowflake:spark-snowflake_{SCALA_VERSION}:{SNOWFLAKE_SPARK_CONNECTOR_VERSION}\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.horizon\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.type\", \"rest\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.uri\", f\"https://{SNOWFLAKE_ACCOUNT_URL}.snowflakecomputing.com/polaris/api/catalog\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.credential\", SNOWFLAKE_ACCOUNTADMIN_TOKEN) \\\n",
    "    .config(\"spark.sql.catalog.horizon.warehouse\", SNOWFLAKE_DATABASE) \\\n",
    "    .config(\"spark.sql.catalog.horizon.scope\", f\"session:role:{SNOWFLAKE_ROLE}\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.header.X-Iceberg-Access-Delegation\",\"vended-credentials\") \\\n",
    "    .config(\"spark.snowflake.sfURL\", SF_URL) \\\n",
    "    .config(\"spark.snowflake.sfUser\", os.getenv('SNOWFLAKE_USER')) \\\n",
    "    .config(\"spark.snowflake.sfPassword\", SNOWFLAKE_FLEET_ANALYST_TOKEN) \\\n",
    "    .config(\"spark.snowflake.sfDatabase\", SNOWFLAKE_DATABASE) \\\n",
    "    .config(\"spark.snowflake.sfSchema\", SNOWFLAKE_SCHEMA) \\\n",
    "    .config(\"spark.snowflake.sfRole\", SNOWFLAKE_ROLE) \\\n",
    "    .config(\"spark.snowflake.sfWarehouse\", SNOWFLAKE_WAREHOUSE) \\\n",
    "    .config(\"spark.sql.iceberg.vectorization.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark session created successfully!\")\n",
    "print(f\"Spark version: {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Available Tables (including Dynamic Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all tables visible to Spark\n",
    "spark.sql(\"SHOW TABLES IN horizon.RAW\").show(truncate=False)\n",
    "spark.sql(\"SHOW TABLES IN horizon.CURATED\").show(truncate=False)\n",
    "spark.sql(\"SHOW TABLES IN horizon.ANALYTICS\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See variant column in Iceberg table\n",
    "spark.sql(\"DESCRIBE TABLE horizon.RAW.VEHICLE_TELEMETRY_STREAM\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Data and Extract VARIANT Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Spark's variant_get() function to extract nested fields from VARIANT\n",
    "# This query succeeds, and no Snowflake compute is used, since there's no masking policy on the Iceberg table.\n",
    "df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        VEHICLE_ID,\n",
    "        EVENT_TIMESTAMP,\n",
    "        variant_get(TELEMETRY_DATA, '$.speed_mph', 'float') AS speed_mph,\n",
    "        variant_get(TELEMETRY_DATA, '$.engine.temperature_f', 'int') AS engine_temp,\n",
    "        variant_get(TELEMETRY_DATA, '$.location.lat', 'float') AS latitude,\n",
    "        variant_get(TELEMETRY_DATA, '$.location.lon', 'float') AS longitude\n",
    "    FROM horizon.RAW.VEHICLE_TELEMETRY_STREAM\n",
    "    WHERE variant_get(TELEMETRY_DATA, '$.speed_mph', 'float') > 60\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Access Control (Masking Enforcement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enforce masking policies from Spark, we need the Snowflake Connector for Spark\n",
    "# which routes queries through Snowflake for policy evaluation\n",
    "# See: https://docs.snowflake.com/en/user-guide/tables-iceberg-query-using-external-query-engine-snowflake-horizon-enforce-access-policies\n",
    "\n",
    "# Stop the previous Spark session first\n",
    "spark.stop()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Configuration\n",
    "SNOWFLAKE_PASSWORD = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "SNOWFLAKE_ROLE = 'FLEET_ANALYST'\n",
    "SNOWFLAKE_SCHEMA = 'RAW'\n",
    "SNOWFLAKE_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE', 'FLEET_ANALYTICS_WH')\n",
    "SF_URL = f\"{SNOWFLAKE_ACCOUNT_URL}.snowflakecomputing.com\"\n",
    "\n",
    "# Versions - Note: Spark 3.5 required for Snowflake Connector masking support\n",
    "SNOWFLAKE_JDBC_VERSION = \"3.24.0\"\n",
    "SNOWFLAKE_SPARK_CONNECTOR_VERSION = \"3.1.6\"\n",
    "\n",
    "spark_analyst = SparkSession.builder \\\n",
    "    .appName(\"Fleet Analytics - Analyst View\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.jars.packages\", \n",
    "            f\"org.apache.iceberg:iceberg-spark-runtime-4.0_{SCALA_VERSION}:{ICEBERG_VERSION},\"\n",
    "            f\"org.apache.iceberg:iceberg-aws-bundle:{ICEBERG_VERSION},\"\n",
    "            f\"net.snowflake:snowflake-jdbc:{SNOWFLAKE_JDBC_VERSION},\"\n",
    "            f\"net.snowflake:spark-snowflake_{SCALA_VERSION}:{SNOWFLAKE_SPARK_CONNECTOR_VERSION}\") \\\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "    .config(\"spark.sql.defaultCatalog\", \"horizon\") \\\n",
    "    .config(\"spark.sql.catalog.horizon\", \"org.apache.spark.sql.snowflake.catalog.SnowflakeFallbackCatalog\") \\\n",
    "    # .config(\"spark.sql.catalog.horizon.catalog-impl\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.type\", \"rest\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.uri\", f\"https://{SNOWFLAKE_ACCOUNT_URL}.snowflakecomputing.com/polaris/api/catalog\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.warehouse\", SNOWFLAKE_DATABASE) \\\n",
    "    .config(\"spark.sql.catalog.horizon.scope\", f\"session:role:{SNOWFLAKE_ROLE}\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.credential\", SNOWFLAKE_FLEET_ANALYST_TOKEN) \\\n",
    "    .config(\"spark.sql.catalog.horizon.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "    .config(\"spark.sql.catalog.horizon.header.X-Iceberg-Access-Delegation\", \"vended-credentials\") \\\n",
    "    .config(\"spark.snowflake.sfURL\", SF_URL) \\\n",
    "    .config(\"spark.snowflake.sfUser\", os.getenv('SNOWFLAKE_USER')) \\\n",
    "    .config(\"spark.snowflake.sfPassword\", SNOWFLAKE_FLEET_ANALYST_TOKEN) \\\n",
    "    .config(\"spark.snowflake.sfDatabase\", SNOWFLAKE_DATABASE) \\\n",
    "    .config(\"spark.snowflake.sfSchema\", SNOWFLAKE_SCHEMA) \\\n",
    "    .config(\"spark.snowflake.sfRole\", SNOWFLAKE_ROLE) \\\n",
    "    .config(\"spark.snowflake.sfWarehouse\", SNOWFLAKE_WAREHOUSE) \\\n",
    "    .config(\"spark.sql.iceberg.vectorization.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_analyst.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still see Iceberg tables via Iceberg REST API\n",
    "spark_analyst.sql(\"SHOW TABLES in horizon.RAW\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When reading an Iceberg table with a maskign policy, Snowflake returns masked results\n",
    "spark_analyst.sql(\"\"\"\n",
    "    SELECT\n",
    "        VEHICLE_ID,\n",
    "        MAKE,\n",
    "        MODEL,\n",
    "        YEAR,\n",
    "        LICENSE_PLATE,\n",
    "        DRIVER_NAME,\n",
    "        DRIVER_EMAIL,\n",
    "        DRIVER_PHONE,\n",
    "        FLEET_REGION\n",
    "    FROM horizon.RAW.VEHICLE_REGISTRY\n",
    "\"\"\").show(truncate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. **Connecting Spark to Snowflake Iceberg Catalog** using REST API\n",
    "2. **Listing and describing tables** including Dynamic Iceberg Tables\n",
    "3. **Querying VARIANT data** with JSON path extraction\n",
    "4. **Access control enforcement** with masking policies applied in Spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
